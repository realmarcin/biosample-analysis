{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dill\n",
      "  Using cached https://files.pythonhosted.org/packages/52/d6/79f40d230895fa1ce3b6af0d22e0ac79c65175dc069c194b79cc8e05a033/dill-0.3.3-py2.py3-none-any.whl\n",
      "Installing collected packages: dill\n",
      "Successfully installed dill-0.3.3\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 21.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "import time\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor, Pool, cv\n",
    "import dill\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "seconds 143.51247096061707\n"
     ]
    }
   ],
   "source": [
    "random_seed = 123\n",
    "\n",
    "\n",
    "print(\"start\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "dfeco = pd.read_parquet(\"./harmonized-table__nonhuman.parquet\")\n",
    "\n",
    "exec_time = (time.time() - start_time)\n",
    "print('seconds ' + str(exec_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7480877, 464)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_eco.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_eco['IFR']\n",
    "print(y)\n",
    "\n",
    "print(\"df_eco \"+str(df_eco.shape))\n",
    "\n",
    "X = df_eco.iloc[:,:-1]\n",
    "\n",
    "print(\"X \"+str(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_seed) #, random_state=9# The seed was 'chosen' so test and training contain all labels: rn=3,4,8,9\n",
    "print(\"train label deficit:\",len(set(y)-set(y_train)),\"test label deficit:\",len(set(y)-set(y_test)))\n",
    "\n",
    "print(\"shapes \"+str(X_train.shape)+\"\\t\"+str(X_test.shape)+\"\\t\"+str(y_train.shape)+\"\\t\"+str(y_test.shape))\n",
    "\n",
    "train_dataset = Pool(X_train, y_train)\n",
    "test_dataset = Pool(X_test, y_test)\n",
    "\n",
    "input_data_dump = [X, y, X_train, X_test, y_train, y_test]\n",
    "pickle.dump(input_data_dump,open(\"input_data_dump\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelstart = time.time()\n",
    "\n",
    "print(f\"Starting search at {modelstart}\")\n",
    "cb_model = CatBoostRegressor(loss_function='MAE',\n",
    "                             iterations = 200,\n",
    "                             verbose = 5,\n",
    "                             learning_rate = 0.1,\n",
    "                             depth = 3,\n",
    "                             l2_leaf_reg = 0.5,\n",
    "                             #eval_metric = 'MCC',\n",
    "                             random_seed = random_seed,\n",
    "                             #bagging_temperature = 0.2,\n",
    "                             #od_type = 'Iter',\n",
    "                             #od_wait = 100\n",
    ")\n",
    "\n",
    "grid = {#'iterations': [100, 150, 200],\n",
    "       'learning_rate': [0.175, 0.2, 0.25],\n",
    "        'depth': [3, 4, 5],\n",
    "        'l2_leaf_reg': [2, 2.5, 2.75]}\n",
    "grid_search_result = cb_model.grid_search(grid, train_dataset)\n",
    "\n",
    "lr = grid_search_result['params']['learning_rate']\n",
    "de = grid_search_result['params']['depth']\n",
    "l2 = grid_search_result['params']['l2_leaf_reg']\n",
    "\n",
    "print(f\"Trained grid search in {time.time() - modelstart}s\")\n",
    "\n",
    "print(\"lr, de, l2 \"+str(lr)+\", \"+str(de)+\", \"+str(l2))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelstart = time.time()\n",
    "\n",
    "print(f\"Starting search at {modelstart}\")\n",
    "cb_model = CatBoostRegressor(loss_function='MAE',\n",
    "                             iterations = 200,\n",
    "                             verbose = 5,\n",
    "                             learning_rate = 0.1,\n",
    "                             depth = 3,\n",
    "                             l2_leaf_reg = 0.5,\n",
    "                             #eval_metric = 'MCC',\n",
    "                             random_seed = random_seed,\n",
    "                             #bagging_temperature = 0.2,\n",
    "                             #od_type = 'Iter',\n",
    "                             #od_wait = 100\n",
    ")\n",
    "\n",
    "grid = {#'iterations': [100, 150, 200],\n",
    "       'learning_rate': [0.175, 0.2, 0.25],\n",
    "        'depth': [3, 4, 5],\n",
    "        'l2_leaf_reg': [2, 2.5, 2.75]}\n",
    "grid_search_result = cb_model.grid_search(grid, train_dataset)\n",
    "\n",
    "lr = grid_search_result['params']['learning_rate']\n",
    "de = grid_search_result['params']['depth']\n",
    "l2 = grid_search_result['params']['l2_leaf_reg']\n",
    "\n",
    "print(f\"Trained grid search in {time.time() - modelstart}s\")\n",
    "\n",
    "print(\"lr, de, l2 \"+str(lr)+\", \"+str(de)+\", \"+str(l2))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = cb_model.predict(X_train)\n",
    "rmseT = (np.sqrt(mean_squared_error(y_train, pred_train)))\n",
    "r2T = r2_score(y_train, pred_train)\n",
    "print(\"Testing performance:\")\n",
    "print('RMSE training: {:.2f}'.format(rmseT))\n",
    "print('R2 training: {:.2f}'.format(r2T))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbmf.feature_names = df_eco.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = cb_model.predict(X_test)\n",
    "rmse = (np.sqrt(mean_squared_error(y_test, pred_test)))\n",
    "r2 = r2_score(y_test, pred_test)\n",
    "print(\"Testing performance:\")\n",
    "print('RMSE: {:.2f}'.format(rmse))\n",
    "print('R2: {:.2f}'.format(r2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_model = shap.TreeExplainer(cb_model)\n",
    "explainer_fit = shap.TreeExplainer(cbmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output = [random_seed, cb_model, cbmf, pred_train, explainer_model, pred_test, explainer_fit]\n",
    "pickle.dump(data_output,open(\"data_output_mocci_MAE\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_feature_importance = cb_model.feature_importances_.argsort()\n",
    "plt.barh(cb_model.feature_names[sorted_feature_importance[1:100]],\n",
    "        cb_model.feature_importances_[sorted_feature_importance[1:100]],\n",
    "        color='turquoise')\n",
    "plt.xlabel(\"CatBoost Feature Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer_model.shap_values(X_train)\n",
    "shap.summary_plot(shap_values, X_train, feature_names = cb_model.feature_names[sorted_feature_importance],show=False)#,matplotlib=True).savefig('SHAP.pdf',bbox_inches = 'tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbmf_all = cb_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all = cbmf_all.predict(X)\n",
    "rmseA = (np.sqrt(mean_squared_error(y, pred_all)))\n",
    "r2A = r2_score(y, pred_all)\n",
    "print(\"All performance:\")\n",
    "print('RMSE training: {:.2f}'.format(rmseA))\n",
    "print('R2 training: {:.2f}'.format(r2A))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_all = shap.TreeExplainer(cbmf_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_all = explainer_all.shap_values(X)\n",
    "shap.summary_plot(shap_values_all, X, feature_names = cb_model.feature_names[sorted_feature_importance],show=False)#,matplotlib=True).savefig('SHAP.pdf',bbox_inches = 'tight')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
